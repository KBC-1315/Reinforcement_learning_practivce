{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 붉은 벽 그리기\n",
    "plt.plot([1,1], [0,1], color = 'red', linewidth=2)\n",
    "plt.plot([1,2], [2,2], color = 'red', linewidth=2)\n",
    "plt.plot([2,2], [2,1], color = 'red', linewidth=2)\n",
    "plt.plot([2,3], [1,1], color = 'red', linewidth=2)\n",
    "\n",
    "plt.text(0.5, 2.5, \"S0\", size = 14, ha ='center')\n",
    "plt.text(1.5, 2.5, \"S1\", size = 14, ha ='center')\n",
    "plt.text(2.5, 2.5, \"S2\", size = 14, ha ='center')\n",
    "plt.text(0.5, 1.5, \"S3\", size = 14, ha ='center')\n",
    "plt.text(1.5, 1.5, \"S4\", size = 14, ha ='center')\n",
    "plt.text(2.5, 1.5, \"S5\", size = 14, ha ='center')\n",
    "plt.text(0.5, 0.5, \"S6\", size = 14, ha ='center')\n",
    "plt.text(1.5, 0.5, \"S7\", size = 14, ha ='center')\n",
    "plt.text(2.5, 0.5, \"S8\", size = 14, ha ='center')\n",
    "plt.text(0.5, 2.3, \"START\", size = 14, ha ='center')\n",
    "plt.text(2.5, 0.3, \"GOAL\", size = 14, ha ='center')\n",
    "\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis = \"both\", which ='both', bottom = False, top = False, labelbottom = False, right = False, left = False, labelleft = False)\n",
    "\n",
    "line, =ax.plot([0.5], [2.5], marker = \"o\", color = 'g', markersize = 60)\n",
    "\n",
    "# 정책을 결정하는 파라미터의 초깃값 theta_0을 설정\n",
    "\n",
    "# 줄은 상태 0~7, 열은 행동 방향(상, 우, 하, 좌)를 나타낸다\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan], # S0\n",
    "                    [np.nan, 1, np.nan, 1], # S1\n",
    "                    [np.nan, np.nan, 1, 1], # S1\n",
    "                    [1, 1, 1, np.nan], # S3\n",
    "                    [np.nan, np.nan, 1, 1], # S4\n",
    "                    [1, np.nan, np.nan, np.nan], # S5\n",
    "                    [1, np.nan, np.nan, np.nan], # S6\n",
    "                    [1, 1, np.nan, np.nan], # S7, S8은 목표 지점이므로 정책이 없다\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행동가치 함수 Q의 초기 상태\n",
    "\n",
    "[a, b] = theta_0.shape # 열과 행의 개수를 변수 a, b에 저장\n",
    "Q = np.random.rand(a, b) * theta_0\n",
    "# * theta0으로 요소 단위 곱셈을 수행, Q에서 벽 방향으로 이동하는 행동에는 nan을 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정책 파라미터 theta_0을 무작위 행동 정책 pi로 변환하는 함수\n",
    "\n",
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    '''단순 비율 계산'''\n",
    "\n",
    "    [m, n] = theta.shape # theta의 행렬 크기를 구함\n",
    "    pi = np.zeros((m, n))\n",
    "    for i in range(0, m) :\n",
    "        pi[i, :] = theta[i, :] / np.nansum(theta[i, :]) # 비율 계산\n",
    "\n",
    "    pi = np.nan_to_num(pi) # nan을 0으로 변환\n",
    "\n",
    "    return pi\n",
    "\n",
    "# 무작위 행동정책 pi_0을 계산\n",
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon-Greedy 알고리즘 구현\n",
    "\n",
    "def get_action(s, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"] \n",
    "\n",
    "    # 행동을 결정\n",
    "    if np.random.rand() < epsilon :\n",
    "        # 확률 epsilon으로 무작위 행동을 선택함\n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else :\n",
    "        # Q값이 최대가 되는 행동을 선택함\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "\n",
    "    # 행동을 인덱스로 변환\n",
    "    if next_direction == \"up\":\n",
    "        action = 0\n",
    "    elif next_direction == \"right\":\n",
    "        action = 1\n",
    "    elif next_direction == \"down\":\n",
    "        action = 2\n",
    "    elif next_direction == \"left\":\n",
    "        action = 3\n",
    "\n",
    "    return action\n",
    "\n",
    "def get_s_next(s, a, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    next_direction = direction[a] # 행동 a의 방향\n",
    "\n",
    "    # 행동으로 다음 상태를 결정\n",
    "    if next_direction == \"up\":\n",
    "        s_next = s - 3 # 위로 이동하면 상태값이 3만큼 줄어든다\n",
    "    elif next_direction == \"right\":\n",
    "        s_next = s + 1 # 오른쪽으로 이동하면 상태값이 1만큼 늘어난다\n",
    "    elif next_direction == \"down\":\n",
    "        s_next = s + 3 # 아래로 이동하면 상태값이 3만큼 늘어난다\n",
    "    elif next_direction == \"left\":\n",
    "        s_next = s - 1 # 왼쪽으로 이동하면 상태값이 1만큼 줄어든다\n",
    "\n",
    "    return s_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsa 알고리즘으로 행동가치 함수 Q를 수정\n",
    "\n",
    "def Sarsa(s, a, r, s_next, a_next, Q, eta, gamma) :\n",
    "    if s_next == 8 : # 목표 지점에 도달한 경우\n",
    "        Q[s, a] = Q[s, a] + eta * (r - Q[s, a])\n",
    "    else :\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gamma * Q[s_next, a_next] - Q[s, a])\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsa 알고리즘으로 미로를 빠져나오는 함수, 상태 및 행동 그리고 Q값의 히스토리를 출력\n",
    "\n",
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0 # 시작 지점\n",
    "    a = a_next = get_action(s, Q, epsilon, pi) # 첫 번째 행동\n",
    "    s_a_history = [[0, np.nan]] # 에이전트의 행동 및 상태의 히스토리를 기록하는 리스트\n",
    "\n",
    "    while (1) : # 목표 지점에 이를 때까지 반복\n",
    "        a = a_next # 행동 결정\n",
    "\n",
    "        s_a_history[-1][1] = a\n",
    "        # 현재 상태(마지막이므로 인덱스가 -1)를 히스토리에 추가\n",
    "\n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "        # 다음 단계의 상태를 구함\n",
    "\n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        # 다음 상태를 히스토리에 추가, 행동은 아직 알 수 없으므로 nan으로 둔다\n",
    "\n",
    "        # 보상을 부여하고 다음 행동을 계산\n",
    "        if s_next == 8:\n",
    "            r = 1 # 목표 지점에 도달했다면 보상을 부여\n",
    "            a_next = np.nan\n",
    "        else :\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            # 다음 행동 a_next를 계산\n",
    "\n",
    "        # 가치함수를 수정\n",
    "        Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "\n",
    "        # 종료 여부 판정\n",
    "        if s_next == 8 : # 목표 지점에 도달하면 종료\n",
    "            break\n",
    "        else :\n",
    "            s = s_next\n",
    "\n",
    "    return [s_a_history, Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에피소드 :1\n",
      "2.130775363928458\n",
      "목표 지점까지의 단계 수 :291\n",
      "에피소드 :2\n",
      "0.04461974950307557\n",
      "목표 지점까지의 단계 수 :15\n",
      "에피소드 :3\n",
      "0.04408832075826963\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :4\n",
      "0.04308700399985288\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :5\n",
      "0.04159125858388024\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :6\n",
      "0.03973248236111521\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :7\n",
      "0.03761877619642695\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :8\n",
      "0.03627192871781121\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :9\n",
      "0.03586720319155995\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :10\n",
      "0.03537784587485354\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :11\n",
      "0.0348068178918568\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :12\n",
      "0.03415896553372899\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :13\n",
      "0.03344046752409113\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :14\n",
      "0.03265838688696793\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :15\n",
      "0.03182031090350823\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :16\n",
      "0.030934064995535693\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :17\n",
      "0.030007488412720773\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :18\n",
      "0.029048261365581363\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :19\n",
      "0.028063774773460726\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :20\n",
      "0.027061035115655607\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :21\n",
      "0.026046598011790545\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :22\n",
      "0.025026525137813116\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :23\n",
      "0.02400635992720912\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :24\n",
      "0.022991118231181162\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :25\n",
      "0.021985290732342788\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :26\n",
      "0.020992854437715924\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :27\n",
      "0.02001729103047456\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :28\n",
      "0.01906161024644204\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :29\n",
      "0.018128376769974364\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :30\n",
      "0.01721973942247812\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :31\n",
      "0.016337461652376484\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :32\n",
      "0.015482952533866445\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :33\n",
      "0.01465729764853474\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :34\n",
      "0.013861289363376939\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :35\n",
      "0.013095456134908146\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :36\n",
      "0.012360090565315063\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :37\n",
      "0.011655276015883453\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :38\n",
      "0.010980911647831104\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :39\n",
      "0.01033673581334249\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :40\n",
      "0.009722347761987549\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :41\n",
      "0.009137227661365155\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :42\n",
      "0.008580754957219106\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :43\n",
      "0.008052225118576284\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :44\n",
      "0.007550864828690496\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :45\n",
      "0.007075845693633953\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :46\n",
      "0.0066262965479840785\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :47\n",
      "0.006201314441844463\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :48\n",
      "0.005799974395970908\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :49\n",
      "0.005421338012459143\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :50\n",
      "0.005064461027720291\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :51\n",
      "0.004728399892598989\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :52\n",
      "0.004412217461769785\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :53\n",
      "0.00411498787119835\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :54\n",
      "0.0038358006786440857\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :55\n",
      "0.003573764338080987\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :56\n",
      "0.003328009074629046\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :57\n",
      "0.003097689222223754\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :58\n",
      "0.0028819850818936343\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :59\n",
      "0.0026801043542137304\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :60\n",
      "0.0024912831953061154\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :61\n",
      "0.0023147869417244893\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :62\n",
      "0.002149910545676925\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :63\n",
      "0.001995978758369543\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :64\n",
      "0.0018523460957680093\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :65\n",
      "0.0017183966178178078\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :66\n",
      "0.001593543549098353\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :67\n",
      "0.0014772287660527184\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :68\n",
      "0.0013689221732956502\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :69\n",
      "0.0012681209890678113\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :70\n",
      "0.0011743489576743205\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :71\n",
      "0.0010871555046803039\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :72\n",
      "0.0010061148487749971\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :73\n",
      "0.0009308250824938691\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :74\n",
      "0.0008609072324500255\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :75\n",
      "0.0007960043083061752\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :76\n",
      "0.0007357803484663306\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :77\n",
      "0.0006799194693108968\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :78\n",
      "0.0006281249237830577\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :79\n",
      "0.0005801181742162154\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :80\n",
      "0.0005356379834746683\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :81\n",
      "0.0004944395277542979\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :82\n",
      "0.000456293533749097\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :83\n",
      "0.00042098544231972124\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :84\n",
      "0.000388314600304418\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :85\n",
      "0.00035809348167437083\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :86\n",
      "0.0003301469388601319\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :87\n",
      "0.0003043114847407491\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :88\n",
      "0.00028043460550886135\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :89\n",
      "0.0002583741043820087\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :90\n",
      "0.00023799747591957132\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :91\n",
      "0.0002191813105393292\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :92\n",
      "0.0002018107286765325\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :93\n",
      "0.0001857788439102448\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :94\n",
      "0.00017098625429123882\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :95\n",
      "0.00015734056102023608\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :96\n",
      "0.00014475591357510087\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :97\n",
      "0.00013315258033597122\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :98\n",
      "0.00012245654372877723\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :99\n",
      "0.00011259911889049956\n",
      "목표 지점까지의 단계 수 :5\n",
      "에피소드 :100\n",
      "0.00010351659484719722\n",
      "목표 지점까지의 단계 수 :5\n"
     ]
    }
   ],
   "source": [
    "# Sarsa 알고리즘으로 미로 빠져나오기\n",
    "\n",
    "eta = 0.1 # 학습률\n",
    "gamma = 0.9 # 시간할인율\n",
    "epsilon = 0.5 # epsilon-greedy 알고리즘 epsilon 초깃값\n",
    "v = np.nanmax(Q, axis = 1) # 각 상태마다 가치의 최댓값을 계산\n",
    "is_continue = True\n",
    "episode = 1\n",
    "\n",
    "while is_continue : # is_continue의 값이 False가 될 때까지 반복\n",
    "    print('에피소드 :'+str(episode))\n",
    "\n",
    "    # epsilon 값을 조금씩 감소시킴\n",
    "    epsilon = epsilon / 2\n",
    "\n",
    "    # Sarsa 알고리즘으로 미로를 빠져나온 후, 결과로 나온 행동 히스토리와 Q값을 변수에 저장\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "\n",
    "    # 상태가치의 변화\n",
    "    new_v = np.nanmax(Q, axis = 1) # 각 상태마다 행동가치의 최댓값을 계산\n",
    "    print(np.sum(np.abs(new_v - v))) # 상태가치 함수의 변화를 출력\n",
    "    v = new_v\n",
    "    print(\"목표 지점까지의 단계 수 :\" + str(len(s_a_history)))\n",
    "\n",
    "    # 100 에피소드 반복\n",
    "    episode += 1\n",
    "    if episode > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
